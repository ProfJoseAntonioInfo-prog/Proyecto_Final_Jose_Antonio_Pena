{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UsGJy3Wp1K6"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# FASE 1: ENTRENAMIENTO DEL MODELO DE IA\n",
        "# ==========================================\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. CONFIGURACI√ìN\n",
        "VOCAB_SIZE = 10000  # Solo usaremos las 10,000 palabras m√°s comunes\n",
        "MAX_LEN = 100       # Cortamos o rellenamos rese√±as a 100 palabras\n",
        "\n",
        "print(\" Descargando y cargando el dataset IMDB...\")\n",
        "# Carga del dataset (ya viene dividido en entrenamiento y prueba)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=VOCAB_SIZE)\n",
        "\n",
        "# 2. PREPROCESAMIENTO (Padding)\n",
        "# Si una rese√±a tiene 50 palabras, le agregamos 50 ceros. Si tiene 200, la cortamos.\n",
        "print(\" Normalizando longitud de las rese√±as...\")\n",
        "x_train = pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_test = pad_sequences(x_test, maxlen=MAX_LEN)\n",
        "\n",
        "# 3. ARQUITECTURA DE LA RED NEURONAL\n",
        "print(\" Construyendo el modelo...\")\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, 16, input_length=MAX_LEN), # Convierte n√∫meros a vectores densos\n",
        "    GlobalAveragePooling1D(),                        # Aplana la informaci√≥n (promedio)\n",
        "    Dense(16, activation='relu'),                    # Capa oculta para aprender patrones\n",
        "    Dense(1, activation='sigmoid')                   # Salida binaria (0=Malo, 1=Bueno)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Resumen de lo que acabamos de construir\n",
        "model.summary()\n",
        "\n",
        "# 4. ENTRENAMIENTO\n",
        "print(\" Iniciando entrenamiento (esto puede tardar unos segundos)...\")\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=5,              # 5 pasadas por todos los datos\n",
        "                    batch_size=512,        # Procesar de 512 en 512\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "# 5. GUARDAR EL MODELO\n",
        "nombre_archivo = \"modelo_sentimientos.h5\"\n",
        "model.save(nombre_archivo)\n",
        "print(f\"\\n ¬°√âXITO! El modelo se ha guardado como '{nombre_archivo}'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PASO EXTRA: DESCARGAR EL MODELO A TU PC\n",
        "# ==========================================\n",
        "from google.colab import files\n",
        "\n",
        "try:\n",
        "    files.download('modelo_sentimientos.h5')\n",
        "    print(\"La descarga deber√≠a comenzar autom√°ticamente.\")\n",
        "except Exception as e:\n",
        "    print(\"Error al descargar: \", e)\n",
        "    print(\"Por favor, usa el panel de la izquierda (carpeta) para descargar manualmente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "U804RKvbqQ88",
        "outputId": "b3188f2f-1d3c-4fc4-84e8-9758061a2e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4a370359-31f9-4716-95c7-9371d1d4c615\", \"modelo_sentimientos.h5\", 1954952)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La descarga deber√≠a comenzar autom√°ticamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# FASE 2: DESPLIEGUE DE LA API (CORREGIDO)\n",
        "# ==========================================\n",
        "\n",
        "!pip install flask pyngrok flask-cors\n",
        "\n",
        "import threading\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok, conf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# 1. PON TU TOKEN DIRECTAMENTE AQU√ç\n",
        "# (Ya he puesto el que me pasaste para facilitarte la vida)\n",
        "NGROK_TOKEN = \"37LcM0paznH2qIyh92kYbKhMIKP_6Rg1Q6jaQbERBCFxYq81t\"\n",
        "\n",
        "# Configuramos ngrok directamente sin preguntar\n",
        "conf.get_default().auth_token = NGROK_TOKEN\n",
        "\n",
        "# 2. CONFIGURAR LA APP FLASK\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "print(\" Cargando modelo entrenado...\")\n",
        "try:\n",
        "    model = load_model('modelo_sentimientos.h5')\n",
        "    print(\" Modelo cargado exitosamente.\")\n",
        "except:\n",
        "    print(\" Error: No se encuentra 'modelo_sentimientos.h5'.\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"API Activa\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        entrada = data.get('secuencia')\n",
        "        if not entrada: return jsonify({'error': 'Falta secuencia'}), 400\n",
        "\n",
        "        entrada_vectorizada = pad_sequences([entrada], maxlen=100)\n",
        "        prediccion = model.predict(entrada_vectorizada)\n",
        "        probabilidad = float(prediccion[0][0])\n",
        "        sentimiento = \"POSITIVA \" if probabilidad > 0.5 else \"NEGATIVA \"\n",
        "\n",
        "        return jsonify({'sentimiento': sentimiento, 'probabilidad': probabilidad})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "# 3. INICIAR SERVIDOR\n",
        "# Matamos procesos previos de ngrok por si acaso\n",
        "ngrok.kill()\n",
        "\n",
        "# Abrimos el t√∫nel\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"\\n ¬°LISTO! TU API EST√Å EN VIVO\")\n",
        "print(f\" COPIA ESTA URL PARA LA FASE 3:  {public_url}\")\n",
        "\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5t3k1z_qXPz",
        "outputId": "a932de75-8a56-4a14-d8fd-851de915f0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Cargando modelo entrenado...\n",
            " Modelo cargado exitosamente.\n",
            "\n",
            "üöÄ ¬°LISTO! TU API EST√Å EN VIVO\n",
            "üåç COPIA ESTA URL PARA LA FASE 3:  https://clippingly-nonreligious-irma.ngrok-free.dev\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2025 18:28:46] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Dec/2025 18:28:46] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# FASE 3: PROBAR LA API (CLIENTE)\n",
        "# ==========================================\n",
        "import requests\n",
        "import json\n",
        "\n",
        "#\n",
        "url_api = \"https://clippingly-nonreligious-irma.ngrok-free.dev\"\n",
        "endpoint = f\"{url_api}/predict\"\n",
        "\n",
        "# Simulamos una rese√±a (ya convertida a n√∫meros para simplificar)\n",
        "# Imagina que estos n√∫meros representan: \"Esta pel√≠cula fue fant√°stica y muy emocionante\"\n",
        "rese√±a_positiva = [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100]\n",
        "\n",
        "payload = {\"secuencia\": rese√±a_positiva}\n",
        "\n",
        "print(f\" Enviando datos a: {endpoint} ...\")\n",
        "\n",
        "try:\n",
        "    response = requests.post(endpoint, json=payload)\n",
        "\n",
        "    print(f\"Estado: {response.status_code}\")\n",
        "    print(\"Respuesta del servidor:\")\n",
        "    print(json.dumps(response.json(), indent=2))\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error al conectar:\", e)"
      ],
      "metadata": {
        "id": "N14BIaJPqnGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}